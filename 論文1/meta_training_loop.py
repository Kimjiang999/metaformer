# meta_training_loop.py

import tensorflow as tf
import numpy as np
from metaformer.metaformer_model import Metaformer
from utils.data_loader import load_all_classes, sample_meta_task

# === æ¨¡å‹èˆ‡è³‡æ–™ ===
meta_model = Metaformer(embed_dim=32)
meta_model.build(input_shape=[(1, 64, 64, 3), (1, 64, 64, 1)])
optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)

# åˆå§‹åŒ– meta_model çš„æ¬Šé‡
dummy_input = tf.random.normal([1, 64, 64, 3])
dummy_saliency = tf.random.normal([1, 64, 64, 1])
meta_model.forward(dummy_input, dummy_saliency, training=False)

loss_fn = tf.keras.losses.MeanSquaredError()

# è¼‰å…¥åˆ†é¡åœ–åƒè³‡æ–™ï¼ˆæ¯é¡è³‡æ–™å¤¾ï¼‰
class_data = load_all_classes("data", image_size=(64, 64), max_per_class=20)

# === MAML Meta-Training å›åœˆ ===
for step in range(1, 101):  # ä½ å¯ä»¥æ”¹ç‚º 1000 æˆ–æ›´å¤š
    class_name, support_set, query_set = sample_meta_task(class_data, n_support=5, n_query=5)

    # === Step 1ï¼šå»ºç«‹ support æ¨¡å‹å‰¯æœ¬
    fast_model = Metaformer(embed_dim=32)

    # å…ˆ dummy é‹è¡Œè®“æ¨¡å‹ build èµ·ä¾†
    dummy_input = tf.random.normal([1, 64, 64, 3])
    dummy_saliency = tf.random.normal([1, 64, 64, 1])
    fast_model.forward(dummy_input, dummy_saliency, training=False)

    fast_model.set_weights(meta_model.get_weights())  # è¤‡è£½åƒæ•¸

    # === Step 2ï¼šåœ¨ support set ä¸Šå¾®èª¿ fast_modelï¼ˆinner loopï¼‰
    for _ in range(1):  # å¯è¨­ç‚ºå¤šæ­¥å¾®èª¿ inner loop
        with tf.GradientTape() as tape:
            saliency = tf.repeat(support_set[..., :1], repeats=3, axis=-1)  # æ¨¡æ“¬ saliency
            recon = fast_model.forward(support_set, saliency, training=True)
            loss = loss_fn(support_set, recon)

        grads = tape.gradient(loss, fast_model.trainable_variables)
        k_opt = tf.keras.optimizers.SGD(learning_rate=0.01)
        k_opt.apply_gradients(zip(grads, fast_model.trainable_variables))

    # === Step 3ï¼šåœ¨ query set ä¸Šè¨ˆç®— meta-loss
    saliency_q = tf.repeat(query_set[..., :1], repeats=3, axis=-1)
    recon_q = fast_model.forward(query_set, saliency_q, training=False)
    meta_loss = loss_fn(query_set, recon_q)

    # === Step 4ï¼šåå‘å‚³é meta-loss â†’ æ›´æ–° meta_modelï¼ˆouter loopï¼‰
    with tf.GradientTape() as meta_tape:
        saliency_s = tf.repeat(support_set[..., :1], repeats=3, axis=-1)
        recon_s = meta_model.forward(support_set, saliency_s, training=True)
        outer_loss = loss_fn(support_set, recon_s)

    meta_grads = meta_tape.gradient(outer_loss, meta_model.trainable_variables)
    optimizer.apply_gradients(zip(meta_grads, meta_model.trainable_variables))

    if step % 10 == 0:
        print(f"Step {step} | Class: {class_name} | Meta-loss: {meta_loss.numpy():.4f}")

# === çµå°¾
# å„²å­˜è¨“ç·´å¾Œåƒæ•¸
meta_model.save_weights("metaformer_meta_trained.weights.h5")
print("ğŸ’¾ Metaformer æ¨¡å‹å·²å„²å­˜ç‚º metaformer_meta_trained.weights.h5")
